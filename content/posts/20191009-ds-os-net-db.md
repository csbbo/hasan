---
title: "DS、Os、 Net 、 DB"
date: 2019-10-09T22:33:24+08:00
draft: true
toc: true
---

数据结构算法，操作系统，计算机网络，数据库总结

<!--more-->
## 数据库(SQL、MySQL、Redis)

### 数据库索引的实现

数据库系统维护着满足一定查找算法的数据结构，这些数据结构以某种方式指向数据，这样就可以在数据库上运行高级查找算法。而这些数据结构就是索引。

#### B树：

一棵m阶B树是一棵平衡的m路查找树，或着它是一棵空树。一棵m阶B树满足以下性质：

1. 如果根节点不是叶子节点，那么它至少有两个子节点
2. 非根非叶子节点最少有ceil(m/2)个子节点
3. 每一个节点最多有 m 个子节点
4. 非叶子节点的节点数比它的键数多一
5. 所有叶子节点在同一层

B树查找，首先从根节点开始二分查找，如果找到则返回相应的数据，否则对相应的区间进行递归查找，找到则成功返回，失败则返回NULL指针。

B树查找效率非常高，一棵m阶B树索引N个key，则树高上限h=log<sub>m</sub>((N+1)/2),所以查找一个key其时间复杂度为O(log<sub>m</sub>N)

#### B+树

B+树是B树的一个变种,跟B树有一下不同：

1. 非叶子节点只做索引，数据都保存在叶子节点中
2. 非叶子节点节点数与关键字个数相同
3. 非叶子节点的子树指针p[i]指向( k[i] , k[i+1] ]
4. 所有叶子节点均有一个链指针指向下一个叶子节点

> MySQL就是利用的B+树实现的索引。

#### 为什么要使用B树、B+树

索引也很大通常以文件形式存储在磁盘上，这样索引查找过程就会产生磁盘IO，所以一个好的索引就需要更少的IO次数和更低的时间复杂度。

减少磁盘IO次数涉及到磁盘存储原理、局部性原理、和磁盘预读。从B树分析，B树检索一次最多需要访问h(树深度)个节点，数据库利用磁盘预读原理将一个节点大小设为等于一个页，这样每个节点只需一次IO就可以全部载入。每次新建节点时也是直接申请一个页的空间，保证一个节点物理上页存储在一个页里。计算机存储分都也是按页对齐的，这就实现每个节点只需一次IO。根据上面B树时间复杂度分析可知其时间复杂度为O(log<sub>m</sub>N)

而像红黑树它的深度h就非常的大，在索引的使用中会造成大量的IO操作。

B+树相对B树来说，它内节点不存储数据因此可以拥有更大的出度，更小的h从而达到更少的IO。

## 数据结构与算法

### 树

#### 二叉树

二叉树是有限个结点的集合，它或为空树或为非空树，对于非空树它是由一个根结点和两株互不相交的二叉树组成，其中一株叫根的做左子树，另一棵叫做根的右子树。

二叉树有以下性质：

+ 性质1：在二叉树中第 i 层的结点数最多为2<sup>i-1</sup>（i ≥ 1）
+ 性质2：高度为k的二叉树其结点总数最多为2<sup>k</sup>-1（ k ≥ 1）
+ 性质3：对任意的非空二叉树 T ，如果叶结点的个数为 n0，而其度为 2 的结点数为 n2，则：n0 = n2 + 1

满二叉树：

深度为k且有2<sup>k</sup>-1结点的二叉树称为满二叉树

完全二叉树：

深度为 k 的，有n个结点的二叉树，当且仅当其每个结点都与深度为 k 的满二叉树中编号从 1 至 n 的结点一一对应，称之为完全二叉树。（除最后一层外，每一层上的节点数均达到最大值；在最后一层上只缺少右边的若干结点）

+ 性质4：具有 n 个结点的完全二叉树的深度为 log2n + 1

> 注意：仅有前序和后序遍历，不能确定一个二叉树，必须有中序遍历的结果

#### 堆

如果一棵完全二叉树的任意一个非终端结点的元素都不小于其左儿子结点和右儿子结点（如果有的话） 的元素，则称此完全二叉树为最大堆。

同样，如果一棵完全二叉树的任意一个非终端结点的元素都不大于其左儿子结点和右儿子结点（如果 有的话）的元素，则称此完全二叉树为最小堆。

> 最大堆的根结点中的元素在整个堆中是最大的；
最小堆的根结点中的元素在整个堆中是最小的。


#### 哈弗曼树

哈夫曼树(Huffman tree)是一类带权路径最短的树，也称最优二叉树。

哈夫曼树的构造规则为：

1. 将w1、w2、…，wn看成是有 n 棵树的森林(每棵树仅有一个结点)；
2. 在森林中选出两个根结点的权值最小的树合并，作为一棵新树的左、右子树，且新树的根结点权值为其左、右子树根结点权值之和；
3. 从森林中删除选取的两棵树，并将新树加入森林；
重复(2)、(3)步，直到森林中只剩一棵树为止，该树即为所求得的哈夫曼树。

#### 二叉搜索树

二叉排序树（Binary Sort Tree）又称二叉查找树（Binary Search Tree），亦称二叉搜索树。
它或者是一棵空树,或者是具有下列性质的二叉树：

+ 若它的左子树不空,则左子树上所有结点的值均小于它的根结点的值；
+ 若它的右子树不空,则右子树上所有结点的值均大于它的根结点的值；
+ 它的左、右子树也分别为二叉搜索树。
+ 没有键值相等的节点

二分查找的时间复杂度是O(log(n))，最坏情况下的时间复杂度是O(n)（相当于顺序查找）

#### 平衡二叉树

平衡二叉树（balanced binary tree）,又称 AVL 树。它是一棵空树,或者是具有如下性质的二叉树：

1. 它的左子树和右子树都是平衡二叉树，
2. 左子树和右子树的深度之差的绝对值不超过1。

平衡二叉树是对二叉搜索树的一种改进。二叉搜索树有一个缺点就是，树的结构是无法预料的，随意性很大，它只与节点的值和插入的顺序有关系，往往得到的是一个不平衡的二叉树。在最坏的情况下，可能得到的是一个单支二叉树，其高度和节点数相同，相当于一个单链表，对其正常的时间复杂度有O(log(n))变成了O(n)，从而丧失了二叉排序树的一些应该有的优点。

#### 红黑树

红黑树（Red–black tree）是一种自平衡二叉搜索树，典型的用途是实现关联数组。

红黑树没有一条路径会比其他路径长出2倍，所以红黑树是近似平衡的，使得红黑树的查找、插入、删除等操作的时间复杂度最坏为O(log n)，但需要注意到在红黑树上执行插入或删除后将不在满足红黑树性质，恢复红黑树的属性需要少量(O(log n))的颜色变更(实际是非常快速的)和不超过三次树旋转(对于插入操作是两次)。虽然插入和删除很复杂，但操作时间仍可以保持为 O(log n) 次。具体如何保证？引出红黑树的5个性质：

1. 每个结点或是红色的或是黑色的
2. 根结点是黑色的
3. 每个叶结点是黑色的
4. 如果一个结点是红色的,则它的两个子结点是黑色的
5. 对于每个结点,从该结点到其后代叶结点的简单路径上,均包含相同数目的黑色结点

#### Trie 树

Trie 树，又称前缀树，字典树， 是一种有序树，用于保存关联数组，其中的键通常是字符串。与二叉查找树不同，键不是直接保存在节点中，而是由节点在树中的位置决定。一个节点的所有子孙都有相同的前缀，也就是这个节点对应的字符串，而根节点对应空字符串。一般情况下，不是所有的节点都有对应的值，只有叶子节点和部分内部节点所对应的键才有相关的值。

Trie 树查询和插入时间复杂度都是 O(n)，是一种以空间换时间的方法。当节点树较多的时候，Trie 树占用的内存会很大。

Trie 树常用于搜索提示。如当输入一个网址，可以自动搜索出可能的选择。当没有完全匹配的搜索结果，可以返回前缀最相似的可能。

### 跳表

跳表(Skip-List)处理的是有序链表，通过建立多层索引每层索引元素个数减少为前一层的一半来提高查找效率。

跳表是一种随机化的数据结构，目前开源软件 Redis和LevelDB 都有用到它，它的效率和红黑树以及 AVL 树不相上下，但跳表的原理相当简单。

### 查找与散列

#### 散列函数的构造

1. 数字分析法
   
    + 从关键字中提取分布比较均匀的若干位作为散列地址
    + 适用情况：事先知道关键字每一位上各种数字分布情况

2. 平方取中法

    + 取关键字平方后中间几位数作为散列地址
    + 适用情况：不能事先了解关键字所有情况，或难以直接从关键字中找到取值较为分散的几位

3. 折叠法

    + 将关键字分割成位数相同的几位，然后去这几位的叠加和（舍去进位）作为散列地址
    + 适用情况：关键字位数较多，而散列地址较少，且难以直接从关键字中找到取值比较分散的几位

4. 除留余数法

    + 一个不大于地址长度m的数p去除关键字，所得余数作为散列地址,即 H(key) = key%p
    + 除留余数法是最常用的构造散列函数方法，也可以在折叠、平方取中等运算之后取模，这样能够保证散列地址一定落在散列表地址空间中

#### 处理冲突

1. 开放地址法

    + 线性探测：H<sub>i</sub>=(H(key)+d<sub>i</sub>)%m 容易产生堆积现象
    + 二次探测（平方探测）：d<sub>i</sub>=1<sup>2</sup> ,-1<sup>2</sup> ,2<sup>2</sup> ,-2<sup>2</sup> ,3<sup>2</sup> ,...,k<sup>2</sup> ,-k<sup>2</sup>(,<=m/2)
    + 随机探测：d<sub>i</sub>采用随机函数得到

2. 链地址法

    + 把具有相同散列地址的记录放在同一单链表中
    + 优点：无堆积、无需事先确定表长、易于删除节点、装填因子a>=1，缺点：需要额外的空间

### 排序算法

#### 稳定性

稳定排序算法会依照相等的关键（换言之就是值）维持纪录的相对次序。也就是一个排序算法是稳定的，就是当有两个有相等关键的纪录R和S，且在原本的串行中R出现在S之前，在排序过的串行中R也将会是在S之前。

#### 计算复杂度（最差、平均、和最好表现）

依据串行（list）的大小（n），一般而言，好的表现是O(nlogn)，且坏的行为是O(n2)。对于一个排序理想的表现是O(n)。仅使用一个抽象关键比较运算的排序算法总平均上总是至少需要O(nlogn)。

所有基于比较的排序的时间复杂度至少是 O(nlogn)。

#### 常见排序算法

常见的稳定排序算法有：

+ 冒泡排序（Bubble Sort） — O(n²)
+ 插入排序（Insertion Sort）— O(n²)
+ 桶排序（Bucket Sort）— O(n); 需要 O(k) 额外空间
+ 计数排序 (Counting Sort) — O(n+k); 需要 O(n+k) 额外空间
+ 合并排序（Merge Sort）— O(nlogn); 需要 O(n) 额外空间
+ 二叉排序树排序 （Binary tree sort） — O(n log n) 期望时间; O(n²)最坏时间; 需要 O(n) 额外空间
+ 基数排序（Radix sort）— O(n·k); 需要 O(n) 额外空间

常见的不稳定排序算法有：

+ 选择排序（Selection Sort）— O(n²)
+ 希尔排序（Shell Sort）— O(nlogn)
+ 堆排序（Heapsort）— O(nlogn)
+ 快速排序（Quicksort）— O(nlogn) 期望时间, O(n²) 最坏情况; 对于大的、乱数串行一般相信是最快的已知排序

#### 具体分析在[另一篇博客](http://hasan.shaobo.fun/posts/20190527-sortAlgorithm/)



### 一致性哈希算法

一致哈希是一种特殊的哈希算法。在使用一致哈希算法后，哈希表槽位数（大小）的改变平均只需要对 K/n个关键字重新映射，其中K是关键字的数量，n是槽位数量。然而在传统的哈希表中，添加或删除一个槽位的几乎需要对所有关键字进行重新映射。

通常的一致性哈希做法是将value映射到一个32位的key值，也即是 0~2<sup>32-1</sup>次方的数值空间；我们可以将这个空间想象成一个首（0）尾（2<sup>32-1</sup>）相接的圆环。

### 熟悉哪些算法

+ [哈希算法] 一致性哈希 time33哈希 FNV1_32_HASH
+ [排序算法] 快速排序
+ [搜索算法] DFS BFS
+ [最小生成树算法] Kruskal Prim
+ [最短路径算法] Dijkstra Floyed

## 操作系统

### 概述

#### 四个基本特征

1. 并发
    并发是指宏观上在一段时间内能同时运行多个程序，而并行则指同一时刻能运行多个指令。

    并行需要硬件支持，如多流水线、多核处理器或者分布式计算系统。

    操作系统通过引入进程和线程，使得程序能够并发运行。

2. 共享

    共享是指系统中的资源可以被多个并发进程共同使用。

    有两种共享方式：互斥共享和同时共享。

    互斥共享的资源称为临界资源，例如打印机等，在同一时刻只允许一个进程访问，需要用同步机制来实现互斥访问。

3. 虚拟

    虚拟技术把一个物理实体转换为多个逻辑实体。

    主要有两种虚拟技术：时（时间）分复用技术和空（空间）分复用技术。

    多个进程能在同一个处理器上并发执行使用了时分复用技术，让每个进程轮流占用处理器，每次只执行一小个时间片并快速切换。

    虚拟内存使用了空分复用技术，它将物理内存抽象为地址空间，每个进程都有各自的地址空间。地址空间的页被映射到物理内存，地址空间的页并不需要全部在物理内存中，当使用到一个没有在物理内存的页时，执行页面置换算法，将该页置换到内存中。

4. 异步

    异步指进程不是一次性执行完毕，而是走走停停，以不可知的速度向前推进。

#### 四个基本功能

1. 进程管理

    进程控制、进程同步、进程通信、死锁处理、处理机调度等。

2. 内存管理

    内存分配、地址映射、内存保护与共享、虚拟内存等。

3. 文件管理

    文件存储空间的管理、目录管理、文件读写管理和保护等。

4. 设备管理

    完成用户的 I/O 请求，方便用户使用各种设备，并提高设备的利用率。

    主要包括缓冲管理、设备分配、设备处理、虛拟设备等。

#### 系统调用

如果一个进程在用户态需要使用内核态的功能，就进行系统调用从而陷入内核，由操作系统代为完成。

Linux 的系统调用主要有以下这些：

Task | Commands
---|---
进程控制|fork(); exit(); wait();
进程通信|pipe(); shmget(); mmap();
文件操作|open(); read(); write();
设备操作|ioctl(); read(); write();
信息维护|getpid(); alarm(); sleep();
安全|chmod(); umask(); chown();

#### 中断分类

1. 外中断

    由 CPU 执行指令以外的事件引起，如 I/O 完成中断，表示设备输入/输出处理已经完成，处理器能够发送下一个输入/输出请求。此外还有时钟中断、控制台中断等。

2. 异常

    由 CPU 执行指令的内部事件引起，如非法操作码、地址越界、算术溢出等。

3. 陷入

    在用户程序中使用系统调用。

### 进程管理

#### 进程与线程

进程：

进程是资源分配的基本单位。

进程控制块 (Process Control Block, PCB) 描述进程的基本信息和运行状态，所谓的创建进程和撤销进程，都是指对 PCB 的操作。

线程：

线程是独立调度的基本单位。

一个进程中可以有多个线程，它们共享进程资源。

QQ 和浏览器是两个进程，浏览器进程里面有很多线程，例如 HTTP 请求线程、事件响应线程、渲染线程等等，线程的并发执行使得在浏览器中点击一个新链接从而发起 HTTP 请求时，浏览器还可以响应用户的其它事件。

区别：

+ 进程是资源分配的基本单位，但是线程不拥有资源，线程可以访问隶属进程的资源。
+ 线程是独立调度的基本单位，在同一进程中，线程的切换不会引起进程切换，从一个进程中的线程切换到另一个进程中的线程时，会引起进程切换。
+ 由于创建或撤销进程时，系统都要为之分配或回收资源，如内存空间、I/O 设备等，所付出的开销远大于创建或撤销线程时的开销。类似地，在进行进程切换时，涉及当前执行进程 CPU 环境的保存及新调度进程 CPU 环境的设置，而线程切换时只需保存和设置少量寄存器内容，开销很小。
+ 线程间可以通过直接读写同一进程中的数据进行通信，但是进程通信需要借助 IPC。

#### 进程状态的切换

+ 就绪状态（ready）：等待被调度
+ 运行状态（running）
+ 阻塞状态（waiting）：等待资源

> 只有就绪态和运行态可以相互转换，其它的都是单向转换。就绪状态的进程通过调度算法从而获得 CPU 时间，转为运行状态；而运行状态的进程，在分配给它的 CPU 时间片用完之后就会转为就绪状态，等待下一次调度。

> 阻塞状态是缺少需要的资源从而由运行状态转换而来，但是该资源不包括 CPU 时间，缺少 CPU 时间会从运行态转换为就绪态。

#### 进程调度算法

不同环境的调度算法目标不同，因此需要针对不同环境来讨论调度算法。

批处理系统:

批处理系统没有太多的用户操作，在该系统中，调度算法目标是保证吞吐量和周转时间（从提交到终止的时间）。

1. 先来先服务 first-come first-serverd（FCFS）
   
   非抢占式的调度算法，按照请求的顺序进行调度。

    有利于长作业，但不利于短作业，因为短作业必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很长时间，造成了短作业等待时间过长。

2. 短作业优先 shortest job first（SJF）

    非抢占式的调度算法，按估计运行时间最短的顺序进行调度。

    长作业有可能会饿死，处于一直等待短作业执行完毕的状态。因为如果一直有短作业到来，那么长作业永远得不到调度。

3. 最短剩余时间优先 shortest remaining time next（SRTN）

    最短作业优先的抢占式版本，按剩余运行时间的顺序进行调度。 当一个新的作业到达时，其整个运行时间与当前进程的剩余时间作比较。如果新的进程需要的时间更少，则挂起当前进程，运行新的进程。否则新的进程等待。

交互式系统：

交互式系统有大量的用户交互操作，在该系统中调度算法的目标是快速地进行响应。

1. 时间片轮转

    将所有就绪进程按 FCFS 的原则排成一个队列，每次调度时，把 CPU 时间分配给队首进程，该进程可以执行一个时间片。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。

    时间片轮转算法的效率和时间片的大小有很大关系：
    
    + 因为进程切换都要保存进程的信息并且载入新进程的信息，如果时间片太小，会导致进程切换得太频繁，在进程切换上就会花过多时间。
    + 而如果时间片过长，那么实时性就不能得到保证。

2. 优先级调度

    为每个进程分配一个优先级，按优先级进行调度。

    为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。

3. 多级反馈队列

    一个进程需要执行 100 个时间片，如果采用时间片轮转调度算法，那么需要交换 100 次。

    多级队列是为这种需要连续执行多个时间片的进程考虑，它设置了多个队列，每个队列时间片大小都不同，例如 1,2,4,8,..。进程在第一个队列没执行完，就会被移到下一个队列。这种方式下，之前的进程只需要交换 7 次。

    每个队列优先权也不同，最上面的优先权最高。因此只有上一个队列没有进程在排队，才能调度当前队列上的进程。

    可以将这种调度算法看成是时间片轮转调度算法和优先级调度算法的结合。

实时系统：

实时系统要求一个请求在一个确定时间内得到响应。

分为硬实时和软实时，前者必须满足绝对的截止时间，后者可以容忍一定的超时。

#### 进程同步

1. 临界区

    对临界资源进行访问的那段代码称为临界区。

    为了互斥访问临界资源，每个进程在进入临界区之前，需要先进行检查。

2. 同步与互斥

   + 同步：多个进程因为合作产生的直接制约关系，使得进程有一定的先后执行关系。
   + 互斥：多个进程在同一时刻只有一个进程能进入临界区。

3. 信号量

    信号量是一个受保护的整型变量，该整型变量在初始化后只能有P原语或V原语来访问修改

    + P(down) : 如果信号量大于 0 ，执行 -1 操作；如果信号量等于 0，进程睡眠，等待信号量大于 0；
    + V(up) ：对信号量执行 +1 操作，唤醒睡眠的进程让其完成 down 操作。

    down 和 up 操作需要被设计成原语，不可分割，通常的做法是在执行这些操作的时候屏蔽中断。

    如果信号量的取值只能为 0 或者 1，那么就成为了 互斥量（Mutex） ，0 表示临界区已经加锁，1 表示临界区解锁。

    使用信号量实现生产者-消费者问题:
    ```c
    #define N 100
    typedef int semaphore;
    semaphore mutex = 1;
    semaphore empty = N;
    semaphore full = 0;

    void producer() {
        while(TRUE) {
            int item = produce_item();
            down(&empty);
            down(&mutex);
            insert_item(item);
            up(&mutex);
            up(&full);
        }
    }

    void consumer() {
        while(TRUE) {
            down(&full);
            down(&mutex);
            int item = remove_item();
            consume_item(item);
            up(&mutex);
            up(&empty);
        }
    }
    ```

4. 管程

    管程是将利用信号量实现的控制代码独立出来，使得客户端代码调用更容易。

    ```Pascal
    // 管程
    monitor ProducerConsumer
        condition full, empty;
        integer count := 0;
        condition c;

        procedure insert(item: integer);
        begin
            if count = N then wait(full);
            insert_item(item);
            count := count + 1;
            if count = 1 then signal(empty);
        end;

        function remove: integer;
        begin
            if count = 0 then wait(empty);
            remove = remove_item;
            count := count - 1;
            if count = N -1 then signal(full);
        end;
    end monitor;

    // 生产者客户端
    procedure producer
    begin
        while true do
        begin
            item = produce_item;
            ProducerConsumer.insert(item);
        end
    end;

    // 消费者客户端
    procedure consumer
    begin
        while true do
        begin
            item = ProducerConsumer.remove;
            consume_item(item);
        end
    end;
    ```

#### 经典同步问题

1. 读者-写者问题

    允许多个进程同时对数据进行读操作，但是不允许读和写以及写和写操作同时发生。

    一个整型变量 count 记录在对数据进行读操作的进程数量，一个互斥量 count_mutex 用于对 count 加锁，一个互斥量 data_mutex 用于对读写的数据加锁。
    ```c
    typedef int semaphore;
    semaphore count_mutex = 1;
    semaphore data_mutex = 1;
    int count = 0;

    void reader() {
        while(TRUE) {
            down(&count_mutex);
            count++;
            if(count == 1) down(&data_mutex); // 第一个读者需要对数据进行加锁，防止写进程访问
            up(&count_mutex);
            read();
            down(&count_mutex);
            count--;
            if(count == 0) up(&data_mutex);
            up(&count_mutex);
        }
    }

    void writer() {
        while(TRUE) {
            down(&data_mutex);
            write();
            up(&data_mutex);
        }
    }
    ```

2. 哲学家进餐问题

    ![](img/a9077f06-7584-4f2b-8c20-3a8e46928820.jpg)

    五个哲学家围着一张圆桌，每个哲学家面前放着食物。哲学家的生活有两种交替活动：吃饭以及思考。当一个哲学家吃饭时，需要先拿起自己左右两边的两根筷子，并且一次只能拿起一根筷子。

    五位哲学家进程并发运行时，假如五位哲学家因为饥饿拿起左边筷子，当他们试图去拿右边的筷子会因为无筷子可拿而无限期等待造成死锁现象。

    解决该问题可以采取一下方法之一：

    + 至多只允许同时4位哲学家同时进餐，这样就能保证至少有一位则学家能拿到筷子。
    + 仅当左右两只筷子可用时才允许拿起筷子进餐。
    + 规定奇数号哲学家先拿起他左边筷子，然后再去拿右边的筷子；而偶数号哲学家则相反。

    第二种解决办法：
    ```c
    #define N 5
    #define LEFT (i + N - 1) % N // 左邻居
    #define RIGHT (i + 1) % N    // 右邻居
    #define THINKING 0
    #define HUNGRY   1
    #define EATING   2
    typedef int semaphore;
    int state[N];                // 跟踪每个哲学家的状态
    semaphore mutex = 1;         // 临界区的互斥
    semaphore s[N];              // 每个哲学家一个信号量

    void philosopher(int i) {
        while(TRUE) {
            think();
            take_two(i);
            eat();
            put_two(i);
        }
    }

    void take_two(int i) {
        down(&mutex);
        state[i] = HUNGRY;
        test(i);
        up(&mutex);
        down(&s[i]);
    }

    void put_two(i) {
        down(&mutex);
        state[i] = THINKING;
        test(LEFT);
        test(RIGHT);
        up(&mutex);
    }

    void test(i) {         // 尝试拿起两把筷子
        if(state[i] == HUNGRY && state[LEFT] != EATING && state[RIGHT] !=EATING) {
            state[i] = EATING;
            up(&s[i]);
        }
    }
    ```
#### 进程通信

进程同步与进程通信很容易混淆，它们的区别在于：

+ 进程同步：控制多个进程按一定顺序执行；
+ 进程通信：进程间传输信息。

进程通信是一种手段，而进程同步是一种目的。也可以说，为了能够达到进程同步的目的，需要让进程进行通信，传输一些进程同步所需要的信息。

1. 管道

    管道是通过调用 pipe 函数创建的，fd[0] 用于读，fd[1] 用于写。
    ```c
    #include <unistd.h>
    int pipe(int fd[2]);
    ```

    它具有以下限制：

    + 只支持半双工通信（单向交替传输）；
    + 只能在父子进程或者兄弟进程中使用。

2. FIFO

    也称为命名管道，去除了管道只能在父子进程中使用的限制。
    ```c
    #include <sys/stat.h>
    int mkfifo(const char *path, mode_t mode);
    int mkfifoat(int fd, const char *path, mode_t mode);
    ```

    FIFO 常用于客户-服务器应用程序中，FIFO 用作汇聚点，在客户进程和服务器进程之间传递数据。

3. 消息队列

    相比于 FIFO，消息队列具有以下优点：

    + 消息队列可以独立于读写进程存在，从而避免了 FIFO 中同步管道的打开和关闭时可能产生的困难；
    + 避免了 FIFO 的同步阻塞问题，不需要进程自己提供同步方法；
    + 读进程可以根据消息类型有选择地接收消息，而不像 FIFO 那样只能默认地接收。

4. 信号量

    它是一个计数器，用于为多个进程提供对共享数据对象的访问。

5. 共享存储

    允许多个进程共享一个给定的存储区。因为数据不需要在进程之间复制，所以这是最快的一种 IPC。

    需要使用信号量用来同步对共享存储的访问。

    多个进程可以将同一个文件映射到它们的地址空间从而实现共享内存。另外 XSI 共享内存不是使用文件，而是使用内存的匿名段。

6. 套接字

    与其它通信机制不同的是，它可用于不同机器间的进程通信。

### 死锁

#### 死锁必要条件

+ 互斥：每个资源要么已经分配给了一个进程，要么就是可用的。
+ 占有和等待：已经得到了某个资源的进程可以再请求新的资源。
+ 不可抢占：已经分配给一个进程的资源不能强制性地被抢占，它只能被占有它的进程显式地释放。
+ 环路等待：有两个或者两个以上的进程组成一条环路，该环路中的每个进程都在等待下一个进程所占有的资源。

#### 死锁处理方法

+ 鸵鸟策略
+ 死锁检测与死锁恢复
+ 死锁预防
+ 死锁避免

鸵鸟策略：

把头埋在沙子里，假装根本没发生问题。

因为解决死锁问题的代价很高，因此鸵鸟策略这种不采取任务措施的方案会获得更高的性能。

当发生死锁时不会对用户造成多大影响，或发生死锁的概率很低，可以采用鸵鸟策略。

大多数操作系统，包括 Unix，Linux 和 Windows，处理死锁问题的办法仅仅是忽略它。

死锁检测与死锁恢复：

不试图阻止死锁，而是当检测到死锁发生时，采取措施进行恢复。

1. 每种类型一个资源的死锁检测

    每种类型一个资源的死锁检测算法是通过检测有向图是否存在环来实现，从一个节点出发进行深度优先搜索，对访问过的节点进行标记，如果访问了已经标记的节点，就表示有向图存在环，也就是检测到死锁的发生。

2. 每种类型多个资源的死锁检测

    每个进程最开始时都不被标记，执行过程有可能被标记。当算法结束时，任何没有被标记的进程都是死锁进程。可参考下面的安全状态。

死锁恢复：

+ 利用抢占恢复
+ 利用回滚恢复
+ 通过杀死进程恢复

死锁预防:

就是在程序运行之前预防发生死锁。

1. 破坏互斥条件
   
    例如假脱机打印机技术允许若干个进程同时输出，唯一真正请求物理打印机的进程是打印机守护进程。

2. 破坏占有和等待条件
   
    一种实现方式是规定所有进程在开始执行前请求所需要的全部资源。

3. 破坏不可抢占条件
   
4. 破坏环路等待
   
    给资源统一编号，进程只能按编号顺序来请求资源。

死锁避免：

在程序运行时避免发生死锁。

1. 安全状态

    定义：如果没有死锁发生，并且即使所有进程突然请求对资源的最大需求，也仍然存在某种调度次序能够使得每一个进程运行完毕，则称该状态是安全的。

    安全状态的检测与死锁的检测类似，因为安全状态必须要求不能发生死锁。下面的银行家算法与死锁检测算法非常类似，可以结合着做参考对比。

2. 单个资源的银行家算法

    一个小城镇的银行家，他向一群客户分别承诺了一定的贷款额度，算法要做的是判断对请求的满足是否会进入不安全状态，如果是，就拒绝请求；否则予以分配。

3. 多个资源的银行家算法

    检查一个状态是否安全的算法如下：

    查找右边的矩阵是否存在一行小于等于向量 A。如果不存在这样的行，那么系统将会发生死锁，状态是不安全的。
    假若找到这样一行，将该进程标记为终止，并将其已分配资源加到 A 中。
    重复以上两步，直到所有进程都标记为终止，则状态时安全的。

### 内存管理

#### 虚拟内存

虚拟内存的目的是为了让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存。

操作系统将内存抽象成地址空间。每个程序拥有自己的地址空间，这个地址空间被分割成多个块，每一块称为一页。这些页被映射到物理内存，但不需要映射到连续的物理内存，也不需要所有页都必须在物理内存中。当程序引用到不在物理内存中的页时，由硬件执行必要的映射，将缺失的部分装入物理内存并重新执行失败的指令。

也就是说一个程序不需要全部调入内存就可以运行，这使得有限的内存运行大程序成为可能。

#### 分页系统地址映射

内存管理单元（MMU）管理着地址空间和物理内存的转换，其中的页表（Page table）存储着页（程序地址空间）和页框（物理内存空间）的映射表。

一个虚拟地址分成两个部分，一部分存储页面号，一部分存储偏移量。

#### 页面置换算法

页面置换算法的主要目标是使页面置换频率最低（也可以说缺页率最低）。

1. 最佳(Optimal)置换算法

    最佳页面置换算法是一种理想型的页面置换算法可保证最低的缺页率。其选择的被淘汰页面是以后永不使用或是在将来长时间不再被访问的页面。

    系统无法确定那个页面是未来长时间不使用的，因此该算法无法实现，但是可以用它去评价其他算法的优劣。

2. 先进先出(FIFO)置换算法

    选择换出的页面是最先进入的页面。

    该算法会将那些经常被访问的页面也被换出，从而使缺页率升高。

3. 最近最久未使用(LRU)置换算法

    由于无法预测各页面将来的使用情况，只能利用”最近的过去“作为”最近的将来“的近似，LRU置换算法是选择最近最久未使用的页面来淘汰。

    LRU算法的实现需要硬件支持，可采用以下方式来实现。

    + 计时法：为每个页面设置一个计时器，选择计时器中值最大的页面淘汰。
    + 移位寄存器法：为每个页面设置一个移位寄存器，初值为0，当进程访问该页时寄存器最高位置1，然后每隔一段时间右移一位，最久未使用页面即寄存器值最小页面。
    + 堆栈法：用一个堆栈来存放内存中页面的页号，访问一次就调整一次使得栈顶始终是最新被访问页面的页号，而栈底则是最久未使用页号。

4. 简单时钟(Clock)置换算法

    为每页设置一个访问位，再将内存中的所有页面都通过链接指针链接成一个循环队列。当某也被访问时，其访问位被置1，在选择一个页面淘汰时检查其访问位，如果是0则换出，若为1则置0暂时不换出。

5. 改进型时钟置换算法

    相对于简单时钟置换算法，改进型时钟置换算法还需添加一个修改因素即置换代价。在选择页面换出时既要是未使用过的页面，有要是未被修改过的页面。

#### 分段

虚拟内存采用的是分页技术，也就是将地址空间划分成固定大小的页，每一页再与内存进行映射。

分段的做法是把每个表分成段，一个段构成一个独立的地址空间。每个段的长度可以不同，并且可以动态增长。

#### 段页式

程序的地址空间划分成多个拥有独立地址空间的段，每个段上的地址空间划分成大小相同的页。这样既拥有分段系统的共享和保护，又拥有分页系统的虚拟内存功能。

#### 分页与分段的比较

+ 对程序员的透明性：分页透明，但是分段需要程序员显式划分每个段。

+ 地址空间的维度：分页是一维地址空间，分段是二维的。

+ 大小是否可以改变：页的大小不可变，段的大小可以动态改变。

+ 出现的原因：分页主要用于实现虚拟内存，从而获得更大的地址空间；分段主要是为了使程序和数据可以被划分为逻辑上独立的地址空间并且有助于共享和保护。

### 设备管理(磁盘)

#### 磁盘结构

+ 盘面（Platter）：一个磁盘有多个盘面；
+ 磁道（Track）：盘面上的圆形带状区域，一个盘面可以有多个磁道；
+ 扇区（Track Sector）：磁道上的一个弧段，一个磁道可以有多个扇区，它是最小的物理储存单位，目前主要有 512 bytes 与 4 K 两种大小；
+ 磁头（Head）：与盘面非常接近，能够将盘面上的磁场转换为电信号（读），或者将电信号转换为盘面的磁场（写）；
+ 制动手臂（Actuator arm）：用于在磁道之间移动磁头；
+ 主轴（Spindle）：使整个盘面转动。

#### 磁盘调度算法

读写一个磁盘块的时间的影响因素有：

+ 旋转时间（主轴转动盘面，使得磁头移动到适当的扇区上）
+ 寻道时间（制动手臂移动，使得磁头移动到适当的磁道上）
实际的数据传输时间

其中，寻道时间最长，因此磁盘调度的主要目标是使磁盘的平均寻道时间最短。

1. 先来先服务(FCFS)

    按照磁盘请求的顺序进行调度。

    优点是公平和简单。缺点也很明显，因为未对寻道做任何优化，使平均寻道时间可能较长。

2. 最短寻道时间优先(SSTF)

    优先调度与当前磁头所在磁道距离最近的磁道。

    虽然平均寻道时间比较低，但是不够公平。如果新到达的磁道请求总是比一个在等待的磁道请求近，那么在等待的磁道请求会一直等待下去，也就是出现饥饿现象。具体来说，两端的磁道请求更容易出现饥饿现象。

3. 电梯算法(SCAN)

    电梯总是保持一个方向运行，直到该方向没有请求为止，然后改变运行方向。

    电梯算法（扫描算法）和电梯的运行过程类似，总是按一个方向来进行磁盘调度，直到该方向上没有未完成的磁盘请求，然后改变方向。

    因为考虑了移动方向，因此所有的磁盘请求都会被满足，解决了 SSTF 的饥饿问题。

### 链接


#### 编译系统

在 Unix 系统上，由编译器把源文件转换为目标文件,这个过程大致如下：

![](img/b396d726-b75f-4a32-89a2-03a7b6e19f6f.jpg)

+ 预处理阶段：处理以 # 开头的预处理命令；
+ 编译阶段：翻译成汇编文件；
+ 汇编阶段：将汇编文件翻译成可重定位目标文件；
+ 链接阶段：将可重定位目标文件和 printf.o 等单独预编译好的目标文件进行合并，得到最终的可执行目标文件。

#### 静态链接

静态链接器以一组可重定位目标文件为输入，生成一个完全链接的可执行目标文件作为输出。链接器主要完成以下两个任务：

+ 符号解析：每个符号对应于一个函数、一个全局变量或一个静态变量，符号解析的目的是将每个符号引用与一个符号定义关联起来。
+ 重定位：链接器通过把每个符号定义与一个内存位置关联起来，然后修改所有对这些符号的引用，使得它们指向这个内存位置。


#### 目标文件

+ 可执行目标文件：可以直接在内存中执行；
+ 可重定位目标文件：可与其它可重定位目标文件在链接阶段合并，创建一个可执行目标文件；
+ 共享目标文件：这是一种特殊的可重定位目标文件，可以在运行时被动态加载进内存并链接；

#### 动态链接

静态库有以下两个问题：

+ 当静态库更新时那么整个程序都要重新进行链接；
+ 对于 printf 这种标准函数库，如果每个程序都要有代码，这会极大浪费资源。

共享库是为了解决静态库的这两个问题而设计的，在 Linux 系统中通常用 .so 后缀来表示，Windows 系统上它们被称为 DLL。它具有以下特点：

+ 在给定的文件系统中一个库只有一个文件，所有引用该库的可执行目标文件都共享这个文件，它不会被复制到引用它的可执行文件中；
+ 在内存中，一个共享库的 .text 节（已编译程序的机器代码）的一个副本可以被不同的正在运行的进程共享。

## 计算机网络

### 概述

网络把主机连接起来，而互联网是把多种不同的网络连接起来，因此互联网是网络的网络。

#### ISP

互联网服务提供商 ISP 可以从互联网管理机构获得许多 IP 地址，同时拥有通信线路以及路由器等联网设备，个人或机构向 ISP 缴纳一定的费用就可以接入互联网。

目前的互联网是一种多层次 ISP 结构，ISP 根据覆盖面积的大小分为第一层 ISP、区域 ISP 和接入 ISP。互联网交换点 IXP 允许两个 ISP 直接相连而不用经过第三个 ISP。

#### 主机之间的通信方式

客户-服务器（C/S）：客户是服务的请求方，服务器是服务的提供方。

对等（P2P）：不区分客户和服务器。

#### 电路交换与分组交换

1. 电路交换
   
    电路交换用于电话通信系统，两个用户要通信之前需要建立一条专用的物理链路，并且在整个通信过程中始终占用该链路。由于通信的过程中不可能一直在使用传输线路，因此电路交换对线路的利用率很低，往往不到 10%。

2. 分组交换
   
    每个分组都有首部和尾部，包含了源地址和目的地址等控制信息，在同一个传输线路上同时传输多个分组互相不会影响，因此在同一条传输线路上允许同时传输多个分组，也就是说分组交换不需要占用传输线路。

    在一个邮局通信系统中，邮局收到一份邮件之后，先存储下来，然后把相同目的地的邮件一起转发到下一个目的地，这个过程就是存储转发过程，分组交换也使用了存储转发过程。

时延

总时延 = 排队时延 + 处理时延 + 传输时延 + 传播时延

1. 排队时延

    分组在路由器的输入队列和输出队列中排队等待的时间，取决于网络当前的通信量。

2. 处理时延


    主机或路由器收到分组时进行处理所需要的时间，例如分析首部、从分组中提取数据、进行差错检验或查找适当的路由等。

3. 传输时延


    主机或路由器传输数据帧所需要的时间。

    delay = <sup>l(bit)</sup>/<sub>v(bit/s)</sub>
    
    其中 l 表示数据帧的长度，v 表示传输速率。

4. 传播时延
   
    电磁波在信道中传播所需要花费的时间，电磁波传播的速度接近光速。

    delay = <sup>l(m)</sup>/<sub>v(m/s)</sub>

    其中 l 表示信道长度，v 表示电磁波在信道上的传播速度。

#### 计算机网络体系结构

![](img/0fa6c237-a909-4e2a-a771-2c5485cd8ce0.png)

1. 五层协议

    + 应用层 ：为特定应用程序提供数据传输服务，例如 HTTP、DNS 等协议。数据单位为报文。

    + 传输层 ：为进程提供通用数据传输服务。由于应用层协议很多，定义通用的传输层协议就可以支持不断增多的应用层协议。运输层包括两种协议：传输控制协议 TCP，提供面向连接、可靠的数据传输服务，数据单位为报文段；用户数据报协议 UDP，提供无连接、尽最大努力的数据传输服务，数据单位为用户数据报。TCP 主要提供完整性服务，UDP 主要提供及时性服务。

    + 网络层 ：为主机提供数据传输服务。而传输层协议是为主机中的进程提供数据传输服务。网络层把传输层传递下来的报文段或者用户数据报封装成分组。

    + 数据链路层 ：网络层针对的还是主机之间的数据传输服务，而主机之间可以有很多链路，链路层协议就是为同一链路的主机提供数据传输服务。数据链路层把网络层传下来的分组封装成帧。

    + 物理层 ：考虑的是怎样在传输媒体上传输数据比特流，而不是指具体的传输媒体。物理层的作用是尽可能屏蔽传输媒体和通信手段的差异，使数据链路层感觉不到这些差异。

2. OSI

    其中表示层和会话层用途如下：

    + 表示层 ：数据压缩、加密以及数据描述，这使得应用程序不必关心在各台主机中数据内部格式不同的问题。

    + 会话层 ：建立及管理会话。

    五层协议没有表示层和会话层，而是将这些功能留给应用程序开发者处理。

3. TCP/IP

    它只有四层，相当于五层协议中数据链路层和物理层合并为网络接口层。

    TCP/IP 体系结构不严格遵循 OSI 分层概念，应用层可能会直接使用 IP 层或者网络接口层。



4. 数据在各层之间的传递过程
   
    在向下的过程中，需要添加下层协议所需要的首部或者尾部，而在向上的过程中不断拆开首部和尾部。

    路由器只有下面三层协议，因为路由器位于网络核心中，不需要为进程或者应用程序提供服务，因此也就不需要传输层和应用层。

### 物理层

#### 通信方式

根据信息在传输线上的传送方向，分为以下三种通信方式：

+ 单工通信：单向传输
+ 半双工通信：双向交替传输
+ 全双工通信：双向同时传输

#### 带通调制

模拟信号是连续的信号，数字信号是离散的信号。带通调制把数字信号转换为模拟信号。

### 链路层

#### 基本问题

1. 封装成帧

    将网络层传下来的分组添加首部和尾部，用于标记帧的开始和结束。
2. 透明传输

    透明表示一个实际存在的事物看起来好像不存在一样。

    帧使用首部和尾部进行定界，如果帧的数据部分含有和首部尾部相同的内容，那么帧的开始和结束位置就会被错误的判定。需要在数据部分出现首部尾部相同的内容前面插入转义字符。如果数据部分出现转义字符，那么就在转义字符前面再加个转义字符。在接收端进行处理之后可以还原出原始数据。这个过程透明传输的内容是转义字符，用户察觉不到转义字符的存在。

3. 差错检测

    目前数据链路层广泛使用了循环冗余检验（CRC）来检查比特差错。

#### 信道分类

1. 广播信道


    一对多通信，一个节点发送的数据能够被广播信道上所有的节点接收到。

    所有的节点都在同一个广播信道上发送数据，因此需要有专门的控制方法进行协调，避免发生冲突（冲突也叫碰撞）。

    主要有两种控制方法进行协调，一个是使用信道复用技术，一是使用 CSMA/CD 协议。

2. 点对点信道

    一对一通信。

    因为不会发生碰撞，因此也比较简单，使用 PPP 协议进行控制。

#### 信道复用技术

1. 频分复用

    频分复用的所有主机在相同的时间占用不同的频率带宽资源。

2. 时分复用

    时分复用的所有主机在不同的时间占用相同的频率带宽资源。

    使用频分复用和时分复用进行通信，在通信的过程中主机会一直占用一部分信道资源。但是由于计算机数据的突发性质，通信过程没必要一直占用信道资源而不让出给其它用户使用，因此这两种方式对信道的利用率都不高。

3. 统计时分复用

    是对时分复用的一种改进，不固定每个用户在时分复用帧中的位置，只要有数据就集中起来组成统计时分复用帧然后发送。

4. 波分复用

    光的频分复用。由于光的频率很高，因此习惯上用波长而不是频率来表示所使用的光载波。

5. 码分复用

    为每个用户分配 m bit 的码片，并且所有的码片正交，对于任意两个码片S向量和T向量有

    ![](img/308a02e9-3346-4251-8c41-bd5536dab491.png)

    为了讨论方便，取 m=8，设码片  为 00011011。在拥有该码片的用户发送比特 1 时就发送该码片，发送比特 0 时就发送该码片的反码 11100100。

#### CSMA/CD 协议

CSMA/CD 表示载波监听多点接入 / 碰撞检测。

+ 多点接入 ：说明这是总线型网络，许多主机以多点的方式连接到总线上。
+ 载波监听 ：每个主机都必须不停地监听信道。在发送前，如果监听到信道正在使用，就必须等待。
+ 碰撞检测 ：在发送中，如果监听到信道已有其它主机正在发送数据，就表示发生了碰撞。虽然每个主机在发送数据之前都已经监听到信道为空闲，但是由于电磁波的传播时延的存在，还是有可能会发生碰撞。

记端到端的传播时延为 τ，最先发送的站点最多经过 2τ 就可以知道是否发生了碰撞，称 2τ 为 争用期 。只有经过争用期之后还没有检测到碰撞，才能肯定这次发送不会发生碰撞。

#### PPP 协议

互联网用户通常需要连接到某个 ISP 之后才能接入到互联网，PPP 协议是用户计算机和 ISP 进行通信时所使用的数据链路层协议。

PPP 的帧格式：

+ F 字段为帧的定界符
+ A 和 C 字段暂时没有意义
+ FCS 字段是使用 CRC 的检验序列
+ 信息部分的长度不超过 1500

#### MAC 地址

MAC 地址是链路层地址，长度为 6 字节（48 位），用于唯一标识网络适配器（网卡）。

一台主机拥有多少个网络适配器就有多少个 MAC 地址。例如笔记本电脑普遍存在无线网络适配器和有线网络适配器，因此就有两个 MAC 地址。

#### 局域网

局域网是一种典型的广播信道，主要特点是网络为一个单位所拥有，且地理范围和站点数目均有限。

主要有以太网、令牌环网、FDDI 和 ATM 等局域网技术，目前以太网占领着有线局域网市场。

#### 以太网

以太网是一种星型拓扑结构局域网。

早期使用集线器进行连接，集线器是一种物理层设备， 作用于比特而不是帧，当一个比特到达接口时，集线器重新生成这个比特，并将其能量强度放大，从而扩大网络的传输距离，之后再将这个比特发送到其它所有接口。如果集线器同时收到两个不同接口的帧，那么就发生了碰撞。

目前以太网使用交换机替代了集线器，交换机是一种链路层设备，它不会发生碰撞，能根据 MAC 地址进行存储转发。

#### 交换机

交换机具有自学习能力，学习的是交换表的内容，交换表中存储着 MAC 地址到接口的映射。

正是由于这种自学习能力，因此交换机是一种即插即用设备，不需要网络管理员手动配置交换表内容。

#### 虚拟局域网

虚拟局域网可以建立与物理位置无关的逻辑组，只有在同一个虚拟局域网中的成员才会收到链路层广播信息。

使用 VLAN 干线连接来建立虚拟局域网，每台交换机上的一个特殊接口被设置为干线接口，以互连 VLAN 交换机。IEEE 定义了一种扩展的以太网帧格式 802.1Q，它在标准以太网帧上加进了 4 字节首部 VLAN 标签，用于表示该帧属于哪一个虚拟局域网。

### 网络层

#### IP 数据报格式

![](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/85c05fb1-5546-4c50-9221-21f231cdc8c5.jpg)

+ **版本 :** 有 4（IPv4）和 6（IPv6）两个值；
+ **首部长度 :** 占 4 位，因此最大值为 15。值为 1 表示的是 1 个 32 位字的长度，也就是 4 字节。因为固定部分长度为 20 字节，因此该值最小为 5。如果可选字段的长度不是 4 字节的整数倍，就用尾部的填充部分来填充。
+ **区分服务 :** 用来获得更好的服务，一般情况下不使用。

+ **总长度 :** 包括首部长度和数据部分长度。

+ **生存时间 ：** TTL，它的存在是为了防止无法交付的数据报在互联网中不断兜圈子。以路由器跳数为单位，当 TTL 为 0 时就丢弃数据报。

+ **协议 ：** 指出携带的数据应该上交给哪个协议进行处理，例如 ICMP、TCP、UDP 等。

+ **首部检验和 ：** 因为数据报每经过一个路由器，都要重新计算检验和，因此检验和不包含数据部分可以减少计算的工作量。

+ **标识 : ** 在数据报长度过长从而发生分片的情况下，相同数据报的不同分片具有相同的标识符。

+ **片偏移 :** 和标识符一起，用于发生分片的情况。片偏移的单位为 8 字节。

![](img/23ba890e-e11c-45e2-a20c-64d217f83430.png)

#### IP 地址编址方式

IP 地址的编址方式经历了三个历史阶段：

+ 分类
+ 子网划分
+ 无分类

1. 分类
   
    由两部分组成，网络号和主机号，其中不同分类具有不同的网络号长度，并且是固定的。

    IP 地址 ::= {< 网络号 >, < 主机号 >}

2. 子网划分
   
    通过在主机号字段中拿一部分作为子网号，把两级 IP 地址划分为三级 IP 地址。

    IP 地址 ::= {< 网络号 >, < 子网号 >, < 主机号 >}

    要使用子网，必须配置子网掩码。一个 B 类地址的默认子网掩码为 255.255.0.0，如果 B 类地址的子网占两个比特，那么子网掩码为 11111111 11111111 11000000 00000000，也就是 255.255.192.0。

3. 无分类

    无分类编址 CIDR 消除了传统 A 类、B 类和 C 类地址以及划分子网的概念，使用网络前缀和主机号来对 IP 地址进行编码，网络前缀的长度可以根据需要变化。

    IP 地址 ::= {< 网络前缀号 >, < 主机号 >}

    CIDR 的记法上采用在 IP 地址后面加上网络前缀长度的方法，例如 128.14.35.7/20 表示前 20 位为网络前缀。

    CIDR 的地址掩码可以继续称为子网掩码，子网掩码首 1 长度为网络前缀的长度。

    一个 CIDR 地址块中有很多地址，一个 CIDR 表示的网络就可以表示原来的很多个网络，并且在路由表中只需要一个路由就可以代替原来的多个路由，减少了路由表项的数量。把这种通过使用网络前缀来减少路由表项的方式称为路由聚合，也称为**构成超网** 。

    在路由表中的项目由“网络前缀”和“下一跳地址”组成，在查找时可能会得到不止一个匹配结果，应当采用最长前缀匹配来确定应该匹配哪一个。

#### 地址解析协议 ARP

网络层实现主机之间的通信，而链路层实现具体每段链路之间的通信。因此在通信过程中，IP 数据报的源地址和目的地址始终不变，而 MAC 地址随着链路的改变而改变。

ARP 实现由 IP 地址得到 MAC 地址。

每个主机都有一个 ARP 高速缓存，里面有本局域网上的各主机和路由器的 IP 地址到 MAC 地址的映射表。

如果主机 A 知道主机 B 的 IP 地址，但是 ARP 高速缓存中没有该 IP 地址到 MAC 地址的映射，此时主机 A 通过广播的方式发送 ARP 请求分组，主机 B 收到该请求后会发送 ARP 响应分组给主机 A 告知其 MAC 地址，随后主机 A 向其高速缓存中写入主机 B 的 IP 地址到 MAC 地址的映射。

#### 网际控制报文协议 ICMP

ICMP 是为了更有效地转发 IP 数据报和提高交付成功的机会。它封装在 IP 数据报中，但是不属于高层协议。

ICMP 报文分为差错报告报文和询问报文。

1. Ping
    Ping 是 ICMP 的一个重要应用，主要用来测试两台主机之间的连通性。

    Ping 的原理是通过向目的主机发送 ICMP Echo 请求报文，目的主机收到之后会发送 Echo 回答报文。Ping 会根据时间和成功响应的次数估算出数据包往返时间以及丢包率。

2. Traceroute
    Traceroute 是 ICMP 的另一个应用，用来跟踪一个分组从源点到终点的路径。

    Traceroute 发送的 IP 数据报封装的是无法交付的 UDP 用户数据报，并由目的主机发送终点不可达差错报告报文。

    + 源主机向目的主机发送一连串的 IP 数据报。第一个数据报 P1 的生存时间 TTL 设置为 1，当 P1 到达路径上的第一个路由器 R1 时，R1 收下它并把 TTL 减 1，此时 TTL 等于 0，R1 就把 P1 丢弃，并向源主机发送一个 ICMP 时间超过差错报告报文；
    + 源主机接着发送第二个数据报 P2，并把 TTL 设置为 2。P2 先到达 R1，R1 收下后把 TTL 减 1 再转发给 R2，R2 收下后也把 TTL 减 1，由于此时 TTL 等于 0，R2 就丢弃 P2，并向源主机发送一个 ICMP 时间超过差错报文。
    + 不断执行这样的步骤，直到最后一个数据报刚刚到达目的主机，主机不转发数据报，也不把 TTL 值减 1。但是因为数据报封装的是无法交付的 UDP，因此目的主机要向源主机发送 ICMP 终点不可达差错报告报文。
    + 之后源主机知道了到达目的主机所经过的路由器 IP 地址以及到达每个路由器的往返时间。

#### 虚拟专用网 VPN

由于 IP 地址的紧缺，一个机构能申请到的 IP 地址数往往远小于本机构所拥有的主机数。并且一个机构并不需要把所有的主机接入到外部的互联网中，机构内的计算机可以使用仅在本机构有效的 IP 地址（专用地址）。

有三个专用地址块：

+ 10.0.0.0 ~ 10.255.255.255
+ 172.16.0.0 ~ 172.31.255.255
+ 192.168.0.0 ~ 192.168.255.255

VPN 使用公用的互联网作为本机构各专用网之间的通信载体。专用指机构内的主机只与本机构内的其它主机通信；虚拟指好像是，而实际上并不是，它有经过公用的互联网。

#### 网络地址转换 NAT

专用网内部的主机使用本地 IP 地址又想和互联网上的主机通信时，可以使用 NAT 来将本地 IP 转换为全球 IP。

在以前，NAT 将本地 IP 和全球 IP 一一对应，这种方式下拥有 n 个全球 IP 地址的专用网内最多只可以同时有 n 台主机接入互联网。为了更有效地利用全球 IP 地址，现在常用的 NAT 转换表把传输层的端口号也用上了，使得多个专用网内部的主机共用一个全球 IP 地址。使用端口号的 NAT 也叫做网络地址与端口转换 NAPT。

#### 路由器的结构

路由器从功能上可以划分为：路由选择和分组转发。

分组转发结构由三个部分组成：交换结构、一组输入端口和一组输出端口。

#### 路由器分组转发流程

+ 从数据报的首部提取目的主机的 IP 地址 D，得到目的网络地址 N。
+ 若 N 就是与此路由器直接相连的某个网络地址，则进行直接交付；
+ 若路由表中有目的地址为 D 的特定主机路由，则把数据报传送给表中所指明的下一跳路由器；
+ 若路由表中有到达网络 N 的路由，则把数据报传送给路由表中所指明的下一跳路由器；
+ 若路由表中有一个默认路由，则把数据报传送给路由表中所指明的默认路由器；
+ 报告转发分组出错。

#### 路由选择协议

路由选择协议都是自适应的，能随着网络通信量和拓扑结构的变化而自适应地进行调整。

互联网可以划分为许多较小的自治系统 AS，一个 AS 可以使用一种和别的 AS 不同的路由选择协议。

可以把路由选择协议划分为两大类：

+ 自治系统内部的路由选择：RIP 和 OSPF
+ 自治系统间的路由选择：BGP

1. 内部网关协议 RIP
   
    RIP 是一种基于距离向量的路由选择协议。距离是指跳数，直接相连的路由器跳数为 1。跳数最多为 15，超过 15 表示不可达。

    RIP 按固定的时间间隔仅和相邻路由器交换自己的路由表，经过若干次交换之后，所有路由器最终会知道到达本自治系统中任何一个网络的最短距离和下一跳路由器地址。

    距离向量算法：

    + 对地址为 X 的相邻路由器发来的 RIP 报文，先修改报文中的所有项目，把下一跳字段中的地址改为 X，并把所有的距离字段加 1；
    + 对修改后的 RIP 报文中的每一个项目，进行以下步骤：
      + 若原来的路由表中没有目的网络 N，则把该项目添加到路由表中；
      + 否则：若下一跳路由器地址是 X，则把收到的项目替换原来路由表中的项目；否则：若收到的项目中的距离 d 小于路由表中的距离，则进行更新（例如原始路由表项为 Net2, 5, P，新表项为 Net2, 4, X，则更新）；否则什么也不做。
    + 若 3 分钟还没有收到相邻路由器的更新路由表，则把该相邻路由器标为不可达，即把距离置为 16。

    RIP 协议实现简单，开销小。但是 RIP 能使用的最大距离为 15，限制了网络的规模。并且当网络出现故障时，要经过比较长的时间才能将此消息传送到所有路由器。

2. 内部网关协议 OSPF
   
    开放最短路径优先 OSPF，是为了克服 RIP 的缺点而开发出来的。

    开放表示 OSPF 不受某一家厂商控制，而是公开发表的；最短路径优先表示使用了 Dijkstra 提出的最短路径算法 SPF。

    OSPF 具有以下特点：

    + 向本自治系统中的所有路由器发送信息，这种方法是洪泛法。
    + 发送的信息就是与相邻路由器的链路状态，链路状态包括与哪些路由器相连以及链路的度量，度量用费用、距离、时延、带宽等来表示。
    + 只有当链路状态发生变化时，路由器才会发送信息。

    所有路由器都具有全网的拓扑结构图，并且是一致的。相比于 RIP，OSPF 的更新过程收敛的很快。

3. 外部网关协议 BGP
   
BGP（Border Gateway Protocol，边界网关协议）

AS 之间的路由选择很困难，主要是由于：

+ 互联网规模很大；
+ 各个 AS 内部使用不同的路由选择协议，无法准确定义路径的度量；
+ AS 之间的路由选择必须考虑有关的策略，比如有些 AS 不愿意让其它 AS 经过。
BGP 只能寻找一条比较好的路由，而不是最佳路由。

每个 AS 都必须配置 BGP 发言人，通过在两个相邻 BGP 发言人之间建立 TCP 连接来交换路由信息。

### 传输层

网络层只把分组发送到目的主机，但是真正通信的并不是主机而是主机中的进程。传输层提供了进程间的逻辑通信，传输层向高层用户屏蔽了下面网络层的核心细节，使应用程序看起来像是在两个传输层实体之间有一条端到端的逻辑通信信道。

#### UDP 和 TCP 的特点

+ 用户数据报协议 UDP（User Datagram Protocol）是无连接的，尽最大可能交付，没有拥塞控制，面向报文（对于应用程序传下来的报文不合并也不拆分，只是添加 UDP 首部），支持一对一、一对多、多对一和多对多的交互通信。

+ 传输控制协议 TCP（Transmission Control Protocol）是面向连接的，提供可靠交付，有流量控制，拥塞控制，提供全双工通信，面向字节流（把应用层传下来的报文看成字节流，把字节流组织成大小不等的数据块），每一条 TCP 连接只能是点对点的（一对一）。


#### UDP 首部格式

![](img/d4c3a4a1-0846-46ec-9cc3-eaddfca71254.jpg)

首部字段只有 8 个字节，包括源端口、目的端口、长度、检验和。12 字节的伪首部是为了计算检验和临时添加的。

#### TCP 首部格式

![](img/55dc4e84-573d-4c13-a765-52ed1dd251f9.png)

+ **序号 ：** 用于对字节流进行编号，例如序号为 301，表示第一个字节的编号为 301，如果携带的数据长度为 100 字节，那么下一个报文段的序号应为 401。
+ **确认号 ：** 期望收到的下一个报文段的序号。例如 B 正确收到 A 发送来的一个报文段，序号为 501，携带的数据长度为 200 字节，因此 B 期望下一个报文段的序号为 701，B 发送给 A 的确认报文段中确认号就为 701。
+ **数据偏移 ：** 指的是数据部分距离报文段起始处的偏移量，实际上指的是首部的长度。
+ **确认 ACK ：** 当 ACK=1 时确认号字段有效，否则无效。TCP 规定，在连接建立后所有传送的报文段都必须把 ACK 置 1。
+ **同步 SYN ：** 在连接建立时用来同步序号。当 SYN=1，ACK=0 时表示这是一个连接请求报文段。若对方同意建立连接，则响应报文中 SYN=1，ACK=1。
+ **终止 FIN ：** 用来释放一个连接，当 FIN=1 时，表示此报文段的发送方的数据已发送完毕，并要求释放连接。
+ **窗口 ：** 窗口值作为接收方让发送方设置其发送窗口的依据。之所以要有这个限制，是因为接收方的数据缓存空间是有限的。

#### TCP 的三次握手

![](img/e92d0ebc-7d46-413b-aec1-34a39602f787.png)

假设 A 为客户端，B 为服务器端。

+ 首先 B 处于 LISTEN（监听）状态，等待客户的连接请求。
+ A 向 B 发送连接请求报文，SYN=1，ACK=0，选择一个初始的序号 x。
+ B 收到连接请求报文，如果同意建立连接，则向 A 发送连接确认报文，SYN=1，ACK=1，确认号为 x+1，同时也选择一个初始的序号 y。
+ A 收到 B 的连接确认报文后，还要向 B 发出确认，确认号为 y+1，序号为 x+1。
+ B 收到 A 的确认后，连接建立。

#### 三次握手的原因

第三次握手是为了防止失效的连接请求到达服务器，让服务器错误打开连接。

客户端发送的连接请求如果在网络中滞留，那么就会隔很长一段时间才能收到服务器端发回的连接确认。客户端等待一个超时重传时间之后，就会重新请求连接。但是这个滞留的连接请求最后还是会到达服务器，如果不进行三次握手，那么服务器就会打开两个连接。如果有第三次握手，客户端会忽略服务器之后发送的对滞留连接请求的连接确认，不进行第三次握手，因此就不会再次打开连接。

为了初始化Sequence Number的初始值。

三次握手可以初始化Sequence Number的值作为后面通信的序号，确保应用层接收到的数据不会乱序。而向对方发送自己的Sequence Number都需要一个返回确认，确定对方已经收到了自己发送过去的Sequence Number，该过程刚好是需要三次握手。

#### 首次握手隐患--SYN超时

Server收到SYN包后，回复SYN-ACK包未收到ACK确认
导致Server不断重试直到超时，Linux下默认等待63秒（从1开始每次翻倍，重试5次）

恶意程序利用该特点发动SYN Flood攻击，把服务器连接队列耗尽让正常的连接请求不能处理。

针对SYN Flood的防范措施：

+ SYN队列满后，通过tcp_syncookie参数回发SYN cookie,若为正常连接Client会回发SYN cookie，直接建立连接。
+ 修改SYN超时时间。

#### TCP保活机制

建立连接后，Client出现故障

+ Server会向客户端发送保活探测报文，如果未收到响应则继续发送
+ 尝试次数达到保活探测次数仍未收到响应则中断连接

#### TCP 的四次挥手

![](img/f87afe72-c2df-4c12-ac03-9b8d581a8af8.jpg)

以下描述不讨论序号和确认号，因为序号和确认号的规则比较简单。并且不讨论 ACK，因为 ACK 在连接建立之后都为 1。

+ A 发送连接释放报文，FIN=1。
+ B 收到之后发出确认，此时 TCP 属于半关闭状态，B 能向 A 发送数据但是 A 不能向 B 发送数据。
+ 当 B 不再需要连接时，发送连接释放报文，FIN=1。
+ A 收到后发出确认，进入 TIME-WAIT 状态，等待 2 MSL（最大报文存活时间）后释放连接。
+ B 收到 A 的确认后释放连接。

#### 四次挥手的原因

客户端发送了 FIN 连接释放报文之后，服务器收到了这个报文，就进入了 CLOSE-WAIT 状态。这个状态是为了让服务器端发送还未传送完毕的数据，传送完毕之后，服务器会发送 FIN 连接释放报文。

因为是全双工通信，发送方和接收方都需要FIN、ACK报文，而其中一方是被动的所以需要四次挥手。

**TIME_WAIT**

客户端接收到服务器端的 FIN 报文后进入此状态，此时并不是直接进入 CLOSED 状态，还需要等待一个时间计时器设置的时间 2MSL。这么做有两个理由：

+ 确保最后一个确认报文能够到达。如果 B 没收到 A 发送来的确认报文，那么就会重新发送连接释放请求报文，A 等待一段时间就是为了处理这种情况的发生。
+ 等待一段时间是为了让本连接持续时间内所产生的所有报文都从网络中消失，使得下一个新的连接不会出现旧的连接请求报文。

#### 出现大量CLOSE_WAIT的原因

对方关闭Socket连接，我方忙于读或写，没有及时关闭连接。

+ 检查代码，特别是释放资源的代码。
+ 检查配置，特别是处理请求的线程配置。

#### TCP 可靠传输

TCP 使用超时重传来实现可靠传输：如果一个已经发送的报文段在超时时间内没有收到确认，那么就重传这个报文段。

一个报文段从发送再到接收到确认所经过的时间称为往返时间 RTT，加权平均往返时间 RTTs 计算如下：

![](img/rtt.png)

其中，0 ≤ a ＜ 1，RTTs 随着 a 的增加更容易受到 RTT 的影响。

超时时间 RTO 应该略大于 RTTs，TCP 使用的超时时间计算如下：

![](img/rto.png)

其中 RTTd 为偏差的加权平均值。

#### TCP 滑动窗口

窗口是缓存的一部分，用来暂时存放字节流。发送方和接收方各有一个窗口，接收方通过 TCP 报文段中的窗口字段告诉发送方自己的窗口大小，发送方根据这个值和其它信息设置自己的窗口大小。

发送窗口内的字节都允许被发送，接收窗口内的字节都允许被接收。如果发送窗口左部的字节已经发送并且收到了确认，那么就将发送窗口向右滑动一定距离，直到左部第一个字节不是已发送并且已确认的状态；接收窗口的滑动类似，接收窗口左部字节已经发送确认并交付主机，就向右滑动接收窗口。

接收窗口只会对窗口内最后一个按序到达的字节进行确认，例如接收窗口已经收到的字节为 {31, 34, 35}，其中 {31} 按序到达，而 {34, 35} 就不是，因此只对字节 31 进行确认。发送方得到一个字节的确认之后，就知道这个字节之前的所有字节都已经被接收。

![](img/a3253deb-8d21-40a1-aae4-7d178e4aa319.jpg)

#### TCP 流量控制

流量控制是为了控制发送方发送速率，保证接收方来得及接收。

接收方发送的确认报文中的窗口字段可以用来控制发送方窗口大小，从而影响发送方的发送速率。将窗口字段设置为 0，则发送方不能发送数据。

#### TCP 拥塞控制

如果网络出现拥塞，分组将会丢失，此时发送方会继续重传，从而导致网络拥塞程度更高。因此当出现拥塞时，应当控制发送方的速率。这一点和流量控制很像，但是出发点不同。流量控制是为了让接收方能来得及接收，而拥塞控制是为了降低整个网络的拥塞程度。

![](img/51e2ed95-65b8-4ae9-8af3-65602d452a25.jpg)

TCP 主要通过四个算法来进行拥塞控制：慢开始、拥塞避免、快重传、快恢复。

发送方需要维护一个叫做拥塞窗口（cwnd）的状态变量，注意拥塞窗口与发送方窗口的区别：拥塞窗口只是一个状态变量，实际决定发送方能发送多少数据的是发送方窗口。

为了便于讨论，做如下假设：

+ 接收方有足够大的接收缓存，因此不会发生流量控制；
+ 虽然 TCP 的窗口基于字节，但是这里设窗口的大小单位为报文段。

![](img/910f613f-514f-4534-87dd-9b4699d59d31.png)

1. 慢开始与拥塞避免
发送的最初执行慢开始，令 cwnd = 1，发送方只能发送 1 个报文段；当收到确认后，将 cwnd 加倍，因此之后发送方能够发送的报文段数量为：2、4、8 ...

注意到慢开始每个轮次都将 cwnd 加倍，这样会让 cwnd 增长速度非常快，从而使得发送方发送的速度增长速度过快，网络拥塞的可能性也就更高。设置一个慢开始门限 ssthresh，当 cwnd >= ssthresh 时，进入拥塞避免，每个轮次只将 cwnd 加 1。

如果出现了超时，则令 ssthresh = cwnd / 2，然后重新执行慢开始。

2. 快重传与快恢复
   
    在接收方，要求每次接收到报文段都应该对最后一个已收到的有序报文段进行确认。例如已经接收到 M1 和 M2，此时收到 M4，应当发送对 M2 的确认。

    在发送方，如果收到三个重复确认，那么可以知道下一个报文段丢失，此时执行快重传，立即重传下一个报文段。例如收到三个 M2，则 M3 丢失，立即重传 M3。

    在这种情况下，只是丢失个别报文段，而不是网络拥塞。因此执行快恢复，令 ssthresh = cwnd / 2 ，cwnd = ssthresh，注意到此时直接进入拥塞避免。

    慢开始和快恢复的快慢指的是 cwnd 的设定值，而不是 cwnd 的增长速率。慢开始 cwnd 设定为 1，而快恢复 cwnd 设定为 ssthresh。

    ![](img/f61b5419-c94a-4df1-8d4d-aed9ae8cc6d5.png)

### 应用层

#### 域名系统

DNS 是一个分布式数据库，提供了主机名和 IP 地址之间相互转换的服务。这里的分布式数据库是指，每个站点只保留它自己的那部分数据。

域名具有层次结构，从上到下依次为：根域名、顶级域名、二级域名。

DNS 可以使用 UDP 或者 TCP 进行传输，使用的端口号都为 53。大多数情况下 DNS 使用 UDP 进行传输，这就要求域名解析器和域名服务器都必须自己处理超时和重传从而保证可靠性。在两种情况下会使用 TCP 进行传输：

+ 如果返回的响应超过的 512 字节（UDP 最大只支持 512 字节的数据）。
+ 区域传送（区域传送是主域名服务器向辅助域名服务器传送变化的那部分数据）。

#### 文件传送协议

FTP 使用 TCP 进行连接，它需要两个连接来传送一个文件：

+ 控制连接：服务器打开端口号 21 等待客户端的连接，客户端主动建立连接后，使用这个连接将客户端的命令传送给服务器，并传回服务器的应答。
+ 数据连接：用来传送一个文件数据。
  
根据数据连接是否是服务器端主动建立，FTP 有主动和被动两种模式：

+ 主动模式：服务器端主动建立数据连接，其中服务器端的端口号为 20，客户端的端口号随机，但是必须大于 1024，因为 0~1023 是熟知端口号。

+ 被动模式：客户端主动建立数据连接，其中客户端的端口号由客户端自己指定，服务器端的端口号随机。

主动模式要求客户端开放端口号给服务器端，需要去配置客户端的防火墙。被动模式只需要服务器端开放端口号即可，无需客户端配置防火墙。但是被动模式会导致服务器端的安全性减弱，因为开放了过多的端口号。

#### 动态主机配置协议

DHCP (Dynamic Host Configuration Protocol) 提供了即插即用的连网方式，用户不再需要手动配置 IP 地址等信息。

DHCP 配置的内容不仅是 IP 地址，还包括子网掩码、网关 IP 地址。

DHCP 工作过程如下：

1. 客户端发送 Discover 报文，该报文的目的地址为 255.255.255.255:67，源地址为 0.0.0.0:68，被放入 UDP 中，该报文被广播到同一个子网的所有主机上。如果客户端和 DHCP 服务器不在同一个子网，就需要使用中继代理。
2. DHCP 服务器收到 Discover 报文之后，发送 Offer 报文给客户端，该报文包含了客户端所需要的信息。因为客户端可能收到多个 DHCP 服务器提供的信息，因此客户端需要进行选择。
3. 如果客户端选择了某个 DHCP 服务器提供的信息，那么就发送 Request 报文给该 DHCP 服务器。
4. DHCP 服务器发送 Ack 报文，表示客户端此时可以使用提供给它的信息。

#### 远程登录协议

TELNET 用于登录到远程主机上，并且远程主机上的输出也会返回。

TELNET 可以适应许多计算机和操作系统的差异，例如不同操作系统系统的换行符定义。

#### 电子邮件协议

一个电子邮件系统由三部分组成：用户代理、邮件服务器以及邮件协议。

邮件协议包含发送协议和读取协议，发送协议常用 SMTP，读取协议常用 POP3 和 IMAP。

![](img/7b3efa99-d306-4982-8cfb-e7153c33aab4.png)

1. SMTP
   
    SMTP 只能发送 ASCII 码，而互联网邮件扩充 MIME 可以发送二进制文件。MIME 并没有改动或者取代 SMTP，而是增加邮件主体的结构，定义了非 ASCII 码的编码规则。

2. POP3
   
    POP3 的特点是只要用户从服务器上读取了邮件，就把该邮件删除。但最新版本的 POP3 可以不删除邮件。

3. IMAP
   
    IMAP 协议中客户端和服务器上的邮件保持同步，如果不手动删除邮件，那么服务器上的邮件也不会被删除。IMAP 这种做法可以让用户随时随地去访问服务器上的邮件。

#### 常用端口

应用	|应用层协议	|端口号	|传输层协议	|备注
---|---|---|---|---
域名解析|DNS|53|UDP/TCP|长度超过512字节时使用TCP
动态主机配置协议|DHCP|67/68|UDP	
简单网络管理协|SNMP|161/162|UDP	
文件传送协议|FTP|20/21|TCP|控制连接21数据连接20
远程终端协议|TELNET|23|TCP	
超文本传送协议|HTTP|80|TCP	
简单邮件传送协议|SMTP|25|TCP	
邮件读取协议|POP3|110|TCP	
网际报文存取协议|IMAP|143|TCP	

#### Web 页面请求过程

1. DHCP 配置主机信息
   
    + 假设主机最开始没有 IP 地址以及其它信息，那么就需要先使用 DHCP 来获取。
    + 主机生成一个 DHCP 请求报文，并将这个报文放入具有目的端口 67 和源端口 68 的 UDP 报文段中。
    + 该报文段则被放入在一个具有广播 IP 目的地址(255.255.255.255) 和源 IP 地址（0.0.0.0）的 IP 数据报中。
    + 该数据报则被放置在 MAC 帧中，该帧具有目的地址 FF:FF:FF:FF:FF:FF，将广播到与交换机连接的所有设备。
    + 连接在交换机的 DHCP 服务器收到广播帧之后，不断地向上分解得到 IP 数据报、UDP 报文段、DHCP 请求报文，之后生成 DHCP ACK 报文，该报文包含以下信息：IP 地址、DNS 服务器的 IP 地址、默认网关路由器的 IP 地址和子网掩码。该报文被放入 UDP 报文段中，UDP 报文段有被放入 IP 数据报中，最后放入 MAC 帧中。
    + 该帧的目的地址是请求主机的 MAC 地址，因为交换机具有自学习能力，之前主机发送了广播帧之后就记录了 MAC 地址到其转发接口的交换表项，因此现在交换机就可以直接知道应该向哪个接口发送该帧。
    + 主机收到该帧后，不断分解得到 DHCP 报文。之后就配置它的 IP 地址、子网掩码和 DNS 服务器的 IP 地址，并在其 IP 转发表中安装默认网关。

2. ARP 解析 MAC 地址
   
    + 主机通过浏览器生成一个 TCP 套接字，套接字向 HTTP 服务器发送 HTTP 请求。为了生成该套接字，主机需要知道网站的域名对应的 IP 地址。
    + 主机生成一个 DNS 查询报文，该报文具有 53 号端口，因为 DNS 服务器的端口号是 53。
    + 该 DNS 查询报文被放入目的地址为 DNS 服务器 IP 地址的 IP 数据报中。
    + 该 IP 数据报被放入一个以太网帧中，该帧将发送到网关路由器。
    + DHCP 过程只知道网关路由器的 IP 地址，为了获取网关路由器的 MAC 地址，需要使用 ARP 协议。
    + 主机生成一个包含目的地址为网关路由器 IP 地址的 ARP 查询报文，将该 ARP 查询报文放入一个具有广播目的地址（FF:FF:FF:FF:FF:FF）的以太网帧中，并向交换机发送该以太网帧，交换机将该帧转发给所有的连接设备，包括网关路由器。
    + 网关路由器接收到该帧后，不断向上分解得到 ARP 报文，发现其中的 IP 地址与其接口的 IP 地址匹配，因此就发送一个 ARP 回答报文，包含了它的 MAC 地址，发回给主机。

3. DNS 解析域名

    + 知道了网关路由器的 MAC 地址之后，就可以继续 DNS 的解析过程了。
    + 网关路由器接收到包含 DNS 查询报文的以太网帧后，抽取出 IP 数据报，并根据转发表决定该 IP 数据报应该转发的路由器。
    + 因为路由器具有内部网关协议（RIP、OSPF）和外部网关协议（BGP）这两种路由选择协议，因此路由表中已经配置了网关路由器到达 DNS 服务器的路由表项。
    + 到达 DNS 服务器之后，DNS 服务器抽取出 DNS 查询报文，并在 DNS 数据库中查找待解析的域名。
    + 找到 DNS 记录之后，发送 DNS 回答报文，将该回答报文放入 UDP 报文段中，然后放入 IP 数据报中，通过路由器反向转发回网关路由器，并经过以太网交换机到达主机。

1. HTTP 请求页面
   
   + 有了 HTTP 服务器的 IP 地址之后，主机就能够生成 TCP 套接字，该套接字将用于向 Web 服务器发送 HTTP GET 报文。
   + 在生成 TCP 套接字之前，必须先与 HTTP 服务器进行三次握手来建立连接。生成一个具有目的端口 80 的 TCP SYN 报文段，并向 HTTP 服务器发送该报文段。
   + HTTP 服务器收到该报文段之后，生成 TCP SYN ACK 报文段，发回给主机。
   + 连接建立之后，浏览器生成 HTTP GET 报文，并交付给 HTTP 服务器。
   + HTTP 服务器从 TCP 套接字读取 HTTP GET 报文，生成一个 HTTP 响应报文，将 Web 页面内容放入报文主体中，发回给主机。
   + 浏览器收到 HTTP 响应报文后，抽取出 Web 页面内容，之后进行渲染，显示 Web 页面。

## HTTP

### HTTP状态码

**1XX 信息**

+ 100 Continue ：表明到目前为止都很正常，客户端可以继续发送请求或者忽略这个响应。

**2XX 成功**

+ 200 OK

+ 204 No Content ：请求已经成功处理，但是返回的响应报文不包含实体的主体部分。一般在只需要从客户端往服务器发送信息，而不需要返回数据时使用。

+ 206 Partial Content ：表示客户端进行了范围请求，响应报文包含由 Content-Range 指定范围的实体内容。

**3XX 重定向**

+ 301 Moved Permanently ：永久性重定向

+ 302 Found ：临时性重定向

+ 303 See Other ：和 302 有着相同的功能，但是 303 明确要求客户端应该采用 GET 方法获取资源。

+ 注：虽然 HTTP 协议规定 301、302 状态下重定向时不允许把 POST 方法改成 GET 方法，但是大多数浏览器都会在 301、302 和 303 状态下的重定向把 POST 方法改成 GET 方法。

+ 304 Not Modified ：如果请求报文首部包含一些条件，例如：If-Match，If-Modified-Since，If-None-Match，If-Range，If-Unmodified-Since，如果不满足条件，则服务器会返回 304 状态码。

+ 307 Temporary Redirect ：临时重定向，与 302 的含义类似，但是 307 要求浏览器不会把重定向请求的 POST 方法改成 GET 方法。

**4XX 客户端错误**

+ 400 Bad Request ：请求报文中存在语法错误。

+ 401 Unauthorized ：该状态码表示发送的请求需要有认证信息（BASIC 认证、DIGEST 认证）。如果之前已进行过一次请求，则表示用户认证失败。

+ 403 Forbidden ：请求被拒绝。

+ 404 Not Found

**5XX 服务器错误**

+ 500 Internal Server Error ：服务器正在执行请求时发生错误。

+ 503 Service Unavailable ：服务器暂时处于超负载或正在进行停机维护，现在无法处理请求。

### HTTP主体

有 4 种类型的首部字段：通用首部字段、请求首部字段、响应首部字段和实体首部字段。

#### 通用首部字段

首部字段名|说明
---|---
Cache-Control|控制缓存的行为
Connection|控制不再转发给代理的首部字段、管理持久连接
Date|创建报文的日期时间
Pragma|报文指令
Trailer|报文末端的首部一览
Transfer-Encoding|指定报文主体的传输编码方式
Upgrade|升级为其他协议
Via|代理服务器的相关信息
Warning|错误通知

#### 请求首部字段

首部字段名|说明
---|---
Accept|用户代理可处理的媒体类型
Accept-Charset|优先的字符集
Accept-Encoding|优先的内容编码
Accept-Language|优先的语言（自然语言）
Authorization|Web 认证信息
Expect|期待服务器的特定行为
From|用户的电子邮箱地址
Host|请求资源所在服务器
If-Match|比较实体标记（ETag）
If-Modified-Since|比较资源的更新时间
If-None-Match|比较实体标记（与 If-Match 相反）
If-Range|资源未更新时发送实体 Byte 的范围请求
If-Unmodified-Since|比较资源的更新时间（与 If-Modified-Since 相反）
Max-Forwards|最大传输逐跳数
Proxy-Authorization|代理服务器要求客户端的认证信息
Range|实体的字节范围请求
Referer|对请求中 URI 的原始获取方
TE|传输编码的优先级
User-Agent|HTTP 客户端程序的信息

#### 响应首部字段

首部字段名|说明
---|---
Accept-Ranges|是否接受字节范围请求
Age|推算资源创建经过时间
ETag|资源的匹配信息
Location|令客户端重定向至指定 URI
Proxy-Authenticate|代理服务器对客户端的认证信息
Retry-After|对再次发起请求的时机要求
Server	HTTP|服务器的安装信息
Vary|代理服务器缓存的管理信息
WWW-Authenticate|服务器对客户端的认证信息

#### 实体首部字段

首部字段名|说明
---|---
Allow|资源可支持的 HTTP 方法
Content-Encoding|实体主体适用的编码方式
Content-Language|实体主体的自然语言
Content-Length|实体主体的大小
Content-Location|替代对应资源的 URI
Content-MD5|实体主体的报文摘要
Content-Range|实体主体的位置范围
Content-Type|实体主体的媒体类型
Expires|实体主体过期的日期时间
Last-Modified|资源的最后修改日期时间

### 连接管理

1. 短连接与长连接

    当浏览器访问一个包含多张图片的 HTML 页面时，除了请求访问的 HTML 页面资源，还会请求图片资源。如果每进行一次 HTTP 通信就要新建一个 TCP 连接，那么开销会很大。

    长连接只需要建立一次 TCP 连接就能进行多次 HTTP 通信。

    从 HTTP/1.1 开始默认是长连接的，如果要断开连接，需要由客户端或者服务器端提出断开，使用 Connection : close；
    在 HTTP/1.1 之前默认是短连接的，如果需要使用长连接，则使用 Connection : Keep-Alive。

2. 流水线
   
    默认情况下，HTTP 请求是按顺序发出的，下一个请求只有在当前请求收到响应之后才会被发出。由于受到网络延迟和带宽的限制，在下一个请求被发送到服务器之前，可能需要等待很长时间。

    流水线是在同一条长连接上连续发出请求，而不用等待响应返回，这样可以减少延迟。

## Linux IO模型

一个输入操作通常包括两个阶段：

+ 等待数据准备好
+ 向内核进程复制数据

对于一个套接字上的输入输出操作，第一步通常需要等待网络中的数据到达，当所有数据到达时，他被复制到内核的某个缓冲区。第二步就是将数据从内核缓冲区复制到应用进程缓冲区。

### 阻塞式I/O

应用进程被阻塞，直到数据从内核缓冲区复制到应用进程缓冲区中才返回。

应该注意到，在阻塞的过程中，其它应用进程还可以执行，因此阻塞不意味着整个操作系统都被阻塞。因为其它应用进程还可以执行，所以不消耗 CPU 时间，这种模型的 CPU 利用率会比较高。

下图中，recvfrom() 用于接收 Socket 传来的数据，并复制到应用进程的缓冲区 buf 中。这里把 recvfrom() 当成系统调用。

```c
ssize_t recvfrom(int sockfd, void *buf, size_t len, int flags, struct sockaddr *src_addr, socklen_t *addrlen);
```

![](img/1492928416812_4.png)

### 非阻塞式I/O

应用进程执行系统调用之后，内核返回一个错误码。应用进程可以继续执行，但是需要不断的执行系统调用来获知 I/O 是否完成，这种方式称为轮询（polling）。

由于 CPU 要处理更多的系统调用，因此这种模型的 CPU 利用率比较低。

![](img/1492929000361_5.png)

### I/O复用

使用 select 或者 poll 等待数据，并且可以等待多个套接字中的任何一个变为可读。这一过程会被阻塞，当某一个套接字可读时返回，之后再使用 recvfrom 把数据从内核复制到进程中。

它可以让单个进程具有处理多个 I/O 事件的能力。又被称为 Event Driven I/O，即事件驱动 I/O。

如果一个 Web 服务器没有 I/O 复用，那么每一个 Socket 连接都需要创建一个线程去处理。如果同时有几万个连接，那么就需要创建相同数量的线程。相比于多进程和多线程技术，I/O 复用不需要进程线程创建和切换的开销，系统开销更小。

![](img/1492929444818_6.png)

### 信号驱动I/O

应用进程使用 sigaction 系统调用，内核立即返回，应用进程可以继续执行，也就是说等待数据阶段应用进程是非阻塞的。内核在数据到达时向应用进程发送 SIGIO 信号，应用进程收到之后在信号处理程序中调用 recvfrom 将数据从内核复制到应用进程中。

相比于非阻塞式 I/O 的轮询方式，信号驱动 I/O 的 CPU 利用率更高。

![](img/1492929553651_7.png)

### 异步I/O

应用进程执行 aio_read 系统调用会立即返回，应用进程可以继续执行，不会被阻塞，内核会在所有操作完成之后向应用进程发送信号。

异步 I/O 与信号驱动 I/O 的区别在于，异步 I/O 的信号是通知应用进程 I/O 完成，而信号驱动 I/O 的信号是通知应用进程可以开始 I/O。

![](img/1492930243286_8.png)

### 五大I/O模型比较

+ 同步 I/O：将数据从内核缓冲区复制到应用进程缓冲区的阶段（第二阶段），应用进程会阻塞。
+ 异步 I/O：第二阶段应用进程不会阻塞。

同步 I/O 包括阻塞式 I/O、非阻塞式 I/O、I/O 复用和信号驱动 I/O ，它们的主要区别在第一个阶段。

非阻塞式 I/O 、信号驱动 I/O 和异步 I/O 在第一阶段不会阻塞。
