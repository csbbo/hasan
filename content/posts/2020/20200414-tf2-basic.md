---
title: "Tensorflow基础--简单粗暴Tensorflow2学习笔记"
date: 2020-04-14T23:05:17+08:00
categories: ["Tensorflow"]
tags: ["nil"]
toc: true
draft: true
---


<!--more-->

前置知识要求

- [Python基本操作](https://www.liaoxuefeng.com/wiki/1016959663602400/1017063413904832) （赋值、分支及循环语句、使用 import 导入库）；
- [Python的With](https://www.ibm.com/developerworks/cn/opensource/os-cn-pythonwith/index.html)语句 ；
- [NumPy](https://docs.scipy.org/doc/numpy/user/quickstart.html),Python下常用的科学计算库。TensorFlow 与之结合紧密；
- [向量](https://zh.wikipedia.org/wiki/%E5%90%91%E9%87%8F)和[矩阵](https://zh.wikipedia.org/wiki/%E7%9F%A9%E9%98%B5)运算（矩阵的加减法、矩阵与向量相乘、矩阵与矩阵相乘、矩阵的转置等；
- [函数的导数](http://old.pep.com.cn/gzsx/jszx_1/czsxtbjxzy/qrzptgjzxjc/dzkb/dscl/),[多元函数求导](https://zh.wikipedia.org/wiki/%E5%81%8F%E5%AF%BC%E6%95%B0)；
- [线性回归](http://old.pep.com.cn/gzsx/jszx_1/czsxtbjxzy/qrzptgjzxjc/dzkb/dscl/)；
- [梯度下降方法](https://zh.wikipedia.org/wiki/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95)求函数的局部最小值。

### TensorFlow 1+1

可以简单地把TensorFlow当做一个科学计算库类似于Numpy

TensorFlow2默认支持及时执行模式(Eager Excution),在TensorFlow1.X版本中如果要使用及时执行模式需要使用函数`tf.enable_eager_execution()`开启

TensorFlow使用张量(Tensor)来作为基本的数据单位,张量相当于多维数组，可以用来描述数学上的标量(0维数组)、向量(1维数组)、矩阵(2维数组)等，示例如下：

```python
import tensorflow as tf

# 定义一个随机数（标量）
random_float = tf.random.uniform(shape=())

# 定义一个有2个元素的零向量
zero_vector = tf.zeros(shape=(2))

# 定义两个2×2的常量矩阵
A = tf.constant([[1., 2.], [3., 4.]])
B = tf.constant([[5., 6.], [7., 8.]])
```

张量重要的属性是其形状、类型和值，可以通过张量的`shape`、`dtype`属性和`numpy()`方法获得

> TensorFlow中大多数的API会根据输入的值推断张量中元素的类型(默认是tf.float32),可以通过dtype参数指定`zero_vector = tf.zeros(shape=(2), dtype=tf.int32)`,张量的的numpy()方法就是将张量的值转换为numpy的数据类型

TensorFlow里面有大量的操作，使得我们可以使用已有的张量就算生成新的张量

```python
C = tf.add(A, B)    # 计算矩阵A和B的和
D = tf.matmul(A, B) # 计算矩阵A和B的乘积
```

### 自动求导机制

在机器学习中，我们经常需要计算函数的导数，TensorFlow提供了强大的自动求导机制来计算导数。在及时执行模式下，TensorFlow引入了`tf.GradientTape()`这个”求导记录器“来实现自动求导

计算函数$y(x)=x^2$在x等于3时的导数
```python
import tensorflow as tf

x = tf.Variable(initial_value=3.)
with tf.GradientTape() as tape:     # 在 tf.GradientTape() 的上下文内，所有计算步骤都会被记录以用于求导
    y = tf.square(x)
y_grad = tape.gradient(y, x)        # 计算y关于x的导数
print([y, y_grad])
```

输出:
```
[array([9.], dtype=float32), array([6.], dtype=float32)]
```

这里x是初始化为3的一个变量，使用`tf.Variable()`声明，可以通过inital_value参数来指定初始值，变量与普通张量的一个重要区别是其默认能被TensorFlow自动求导机制求导，往往被定义为机器学习模型参数

`tf.GradientTape()`是一个自动求导记录器，只要进入`with tf.GradientTape() as tape`该记录器的上下文环境中，该环境中的所有记录步骤都会被自动记录

在机器学习中更加常见的是多元函数中求偏导数，以及对向量或者矩阵求导，下面是使用`tf.GradientTape()`计算函数$L(w, b) = \|Xw + b - y\|^2 $偏导数在$w = (1, 2)^T, b = 1$时分别对 w, b 的偏导数。其中$X=[]&

<!-- ##### -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
</script>
<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML">
</script>